---
title: ''
date: 26-08-2024
permalink: 
tags:
  - athletica.ai
  - Artificial intelligence
  - Human intelligence
---

<figure align="center">
<img src="../images/build_the_moat_front.png" alt="front_cover_blog_9" style="width:100%" />
<figcaption>Photo generated with Gemini</figcaption>
</figure>

# What the hell is a tech moat?

A tech moat refers to a sustainable competitive advantage in the technology sector—something that makes a company or product very hard to compete with. When someone says _"they have a strong tech moat,"_ they often mean:

<figure class="quote">
  <blockquote>
    They own a key piece of infrastructure, data, or distribution that gives them long-term defensibility, particularly in relation to AI products.
  </blockquote>
</figure>

As of end of June 2025, I believe many businesses are quietly (or loudly) wondering if they’ll be fagocitated by Big Tech. Especially in the AI arena. Every size of company is exposed—some might get acquired (lucky you), but for many others, the ending isn’t as glamorous.

The threat? Someone else doing what you're trying to do, better, faster, and with 100x the resources.

# Feeling the FOMO

You wake up. Coffee in hand. Inbox opens:

<figure class="quote">
  <blockquote>
    🚨 BREAKING: [_insert giant tech company name_] drops __new__ model that goes straight to the top of the benchmarks in [_insert AI task you're just starting to understand_].
  </blockquote>
</figure>

Then you doomscroll X and read:

<figure class="quote">
  <blockquote>
    🔥 NEW RELEASE: Goodbye [_insert old-school software like PowerPoint_], the new [_insert AI-powered do-it-all app_] is here!
  </blockquote>
</figure>

Then a friend texts you. “Have you tried the new tool that turns your spreadsheets into TED Talks?” And a university professor you worked with in 2012 emails you out of the blue: “Can we apply AI to that old dataset?”

If any of that hits close to home—if your week oscillates between panic and total AI nihilism—you’re not alone.

I try to remind myself: _in medio stat virtus_. Moderation. If this resonates, this post is for you.

# Should you pivot from science-first to AI-first?

Tempting, isn’t it?

Throw a model at everything. Sprinkle some “LLM magic” on your pitch deck. Raise funding. See what sticks.

But should you?

Maybe. Maybe not. Depends if you're solving a real problem or chasing a trend.

Because if your product wasn’t compelling _before_ AI, it probably won’t be compelling _with_ AI either. Harsh, but usually true.

# Prior knowledge: still relevant in the age of GPT?

Let’s take a moment.

Why do AI-generated video tools need built-in physics engines? Shouldn't the models “just know”?

Turns out, even for AI, understanding physics takes effort. Time. Training. Compute.

So if we _already know_ a lot about something—like fluid dynamics, medical diagnostics, or materials science—why wouldn’t we bake that knowledge in?

Not doing so feels like watching someone reinvent the wheel with GPT and still ending up with a triangle.

# Overkilling solutions

Whenever you use a model that’s way too big for the problem, you’re not just wasting compute. You're probably also:

- Slowing everything down
- Increasing cost
- Reducing accuracy

And here's the kicker: you're more likely to land in a **local minima**—a “meh” solution—rather than the elegant, efficient, correct one.

Remember the old saying:

<figure class="quote">
  <blockquote>
    Everyone can build a bridge that stands, but it takes an engineer to build a bridge that barely stands.
  </blockquote>
</figure>

Elegance matters. Especially when you're trying to scale.

# Practical ways to build a moat (as of 2025)

So what can you do, realistically?

## Go vertical. Go now.

The general-purpose AI race is not yours to win.

But vertical AI? Niche domains? Now we’re talking.

If you understand a sector deeply—healthcare, logistics, fashion, legal—use that. Build tools that do one thing, very well, for a very specific user. That’s a moat.

## Leverage your company’s protected IP

Do you have:

- Unique data no one else has access to?
- A proprietary dataset you've been sitting on since 2017?
- Annotated edge cases from years of customer support tickets?

Use that. Feed it into your models. Refine with domain knowledge. Defend it with contracts.

## Use your copyright protected material

Original content—videos, text, recordings, documentation—that your company owns outright?

That's gold.

It not only trains your own tools, it protects you from the flood of generic content generated by every other AI startup out there. Your uniqueness becomes a feature, not a liability.

### 🛠️ A Real Example: React Agent Tool with LangGraph

Let’s ground this discussion with a realistic example.

Imagine you’ve built a React-style tool using [LangGraph](https://langgraph.dev/) — the new hotness for building multi-step, memory-aware agents. But instead of chasing the trend, you decided to focus on doing something genuinely useful: a tool that queries your database, cleans the data, and extracts science-backed features.

Not just vibes. Actual logic.

```python
import pydantic
import typing

class FeatureExtractionTool(BaseTool):
    """Extracts domain-specific features from cleaned training data for downstream modeling."""

    name = "feature_extraction"
    description = """
    This tool performs data extraction and feature computation. It runs a performant SQL query 
    to pull relevant data, applies filtering, and computes features such as fatigue indexes, 
    weekly volume trends, or recovery deltas. All metrics are backed by validated exercise 
    physiology research. Output is a structured summary for modeling or visualization.
    """
    args_schema = FeatureExtractionInput  # A nice Pydantic model

    def _run(self, session_id: str) -> dict:
        ...
```

This isn't just fluff. If you've ever worked with a messy database — and let’s face it, they’re all messy — you know what we're talking about: nested JSON fields, poorly-named columns like data_v3_clean, timestamps with 18 decimal places, inconsistent user IDs, and undocumented “temporary” tables that somehow contain 80% of the useful data.

You don’t want your agent poking around with vague goals like “analyze training data,” ending up making ten identical calls with slightly different argument guesses. Agents aren’t mind readers. And trial-and-error is not a moat.

### Numbers at Hand

Let’s get real.

Would you use a 3.5 billion parameter model — like GPT-4o — to digest your HRV data, when you know that it takes exactly *four* variables to describe recovery status for 99% of users?

That’s not a rhetorical question. It’s an efficiency one.

The gold standard in this domain already exists and is well-established:

- You use **60 days of HRV data**.
- You extract a few synthetic features that actually carry information.

Here’s what matters:

1. **Baseline** — your 60-day rolling average.
2. **Current trend** — typically a 7-day rolling average.
3. **Normal range** — rolling standard deviation or coefficient of variation.

That’s it. Now, let’s pause.

Why would you ever want to throw 60 raw data points — timestamps and HRV values — into a massive LLM *just to get a description of your recovery metrics*?

You wouldn’t. Or at least you shouldn’t.

Here’s a much better (and cheaper, and smarter) deal:

1. **Write the tool** that pulls the data from your DB and extracts those features. No guesswork. You know what you’re doing. You’re the expert.
2. **Once that’s done**, bring in the big model. Let it explain, summarize, contextualize, maybe translate that into something meaningful for the user.

This is the real power of hybrid AI systems. Use the small, clean tools to distill knowledge. Use the large, generalist models to *communicate* that knowledge — in tone, in language, in UX.

<figure class="quote">
  <blockquote>
    It's not about *not* using large models.
    It's about not using a bulldozzer to eat your icecream. 🚜 🍦
  </blockquote>
</figure>

Here again a small snippet:

```python
from typing import Literal
from pydantic import BaseModel, Field
import pandas as pd
from sqlalchemy import create_engine, text

# Define the input schema for the tool
class FeatureExtractionInput(BaseModel):
    session_id: str = Field(..., description="Unique identifier for the user or data session")

# Define the tool
class FeatureExtractionTool(BaseTool):
    """
    Extracts domain-specific features from cleaned training data for downstream modeling.
    """

    name = "feature_extraction"
    description = """
    This tool performs data extraction and feature computation. It runs a performant SQL query 
    to pull relevant data, applies filtering, and computes features such as HRV baseline, trend, 
    and variability. All metrics are backed by validated exercise physiology research.
    """
    args_schema = FeatureExtractionInput

    def _run(self, session_id: str) -> dict:
        engine = create_engine("sqlite:///your_database.db")

        # YOUR efficient query example
        query = text("""
            SELECT timestamp, hrv
            FROM recovery_metrics
            WHERE session_id = :sid
              AND hrv IS NOT NULL
              AND timestamp >= DATE('now', '-70 day')
            ORDER BY timestamp ASC
        """)

        # Connect with YOUR own DB
        with engine.connect() as conn:
            df = pd.read_sql(query, conn, params={"sid": session_id})

        "YOUR proprietary logic for processing HRV data"

        return payload
```

### What does the result look like? 



## ⚙️ Knowledge Before Action

So you wrote the query yourself. You know the schema. You know what features matter. And you've probably lost a weekend reading the paper that explains why heart rate recovery in the first 60 seconds post-exercise is actually more predictive than VO2max for your use case.

That matters. A lot.

This is the difference between using AI to automate insight and using it to autopilot confusion.

## 🧠 Write for the Agent

Good docstrings are your friends. Pydantic schemas are your peace treaty with entropy. Typing helps your agent execute tools without falling over every other step. All of this lets LangGraph (or any React-style framework) chain steps without breaking down when it hits slightly malformed input.

So, if you are a science-first company, and you are trying to (or you've been told to) build a tech moat in 2025, my suggestions are:

1. Deep understanding of your domain is your gold mine, not something that is "not relevant anymore",

2. Efficient tools built on structured knowledge: clean, agent-friendly interfaces. Go vertical to the point you know you're getting to a unique position: nobody can build a more sophisticated model on that aspect because you are the world-leading expert on that field. Get to the point where general models just do not work anymore. 

3. Rememeber: AI doesn't replace your expertise — it amplifies it. 

### 🧪 Working in the Knowledge Enterprise

If you're in the science field, then you're working in the **knowledge enterprise**. And as of spring 2025, despite what my Twitter feed might suggest, **AGI is not here**. We haven't reached the point where machines can reason autonomously, draw conclusions from first principles, or invent conceptual frameworks out of nothing.

Instead, we're still relying on humans to interpolate between the known data points, i.e.: to connect the dots. GPTs and other large models are powerful tools, yes, but they don't _fill the gaps_ in knowledge for us. They might help you **generate hypotheses**, **rephrase complexity**, or even **model uncertainty**, but let's be clear: they are trained on the very knowledge you and your peers are producing.

In that sense, these models are mirrors of our collective work, not prophets.

So the best thing you can do today is make your **knowledge legible** to these tools. That doesn't mean dumbing it down. It means wrapping it in structure, in context, and in metadata. Write with clarity. Use standards where possible. Build interfaces—APIs, datasets, simulations, protocols—that are **machine-readable** but **human-reasoned**.

That way, you're not just publishing a PDF to gather dust. You're enabling your ideas to **scale**. You're building knowledge that can be queried, adapted, remixed, and distributed at whatever resolution or density your users actually need.

 





